{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TFGkHLqEctg9"
      },
      "outputs": [],
      "source": [
        "!git clone \"https://github.com/kakaobrain/jejueo.git\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SYC3Lg3-dO00"
      },
      "outputs": [],
      "source": [
        "!git clone \"https://github.com/pytorch/fairseq\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L_8fvNUOfH30"
      },
      "outputs": [],
      "source": [
        "!pip install sentencepiece"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')\n",
        "\n",
        "%cd '/content/gdrive/MyDrive/Tobigs/NLP_conference/'\n",
        "%cd fairseq"
      ],
      "metadata": {
        "id": "DWf6xSx0oCgP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PRKFytusdO6C"
      },
      "outputs": [],
      "source": [
        "!pip install --editable ./"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bYbw6Q6pfnNV",
        "outputId": "8be603ee-ad35-405b-aba1-0c4e976a602b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/Tobigs/NLP_conference/jejueo/translation\n"
          ]
        }
      ],
      "source": [
        "cd /content/gdrive/MyDrive/Tobigs/NLP_conference/jejueo/translation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MgP-l2oshgHs"
      },
      "source": [
        "# STEP 1. bpe segment for training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wi1mpnPxfH1S",
        "outputId": "dee262e6-9d97-4231-b6be-67ec358a4f79"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sentencepiece_trainer.cc(177) LOG(INFO) Running command: --input=data/4k/bpe/bpe.train               --normalization_rule_name=identity               --model_prefix=data/4k/bpe/bpe               --character_coverage=0.995               --vocab_size=4000               --model_type=bpe\n",
            "sentencepiece_trainer.cc(77) LOG(INFO) Starts training with : \n",
            "trainer_spec {\n",
            "  input: data/4k/bpe/bpe.train\n",
            "  input_format: \n",
            "  model_prefix: data/4k/bpe/bpe\n",
            "  model_type: BPE\n",
            "  vocab_size: 4000\n",
            "  self_test_sample_size: 0\n",
            "  character_coverage: 0.995\n",
            "  input_sentence_size: 0\n",
            "  shuffle_input_sentence: 1\n",
            "  seed_sentencepiece_size: 1000000\n",
            "  shrinking_factor: 0.75\n",
            "  max_sentence_length: 4192\n",
            "  num_threads: 16\n",
            "  num_sub_iterations: 2\n",
            "  max_sentencepiece_length: 16\n",
            "  split_by_unicode_script: 1\n",
            "  split_by_number: 1\n",
            "  split_by_whitespace: 1\n",
            "  split_digits: 0\n",
            "  treat_whitespace_as_suffix: 0\n",
            "  allow_whitespace_only_pieces: 0\n",
            "  required_chars: \n",
            "  byte_fallback: 0\n",
            "  vocabulary_output_piece_score: 1\n",
            "  train_extremely_large_corpus: 0\n",
            "  hard_vocab_limit: 1\n",
            "  use_all_vocab: 0\n",
            "  unk_id: 0\n",
            "  bos_id: 1\n",
            "  eos_id: 2\n",
            "  pad_id: -1\n",
            "  unk_piece: <unk>\n",
            "  bos_piece: <s>\n",
            "  eos_piece: </s>\n",
            "  pad_piece: <pad>\n",
            "  unk_surface:  ⁇ \n",
            "}\n",
            "normalizer_spec {\n",
            "  name: identity\n",
            "  add_dummy_prefix: 1\n",
            "  remove_extra_whitespaces: 1\n",
            "  escape_whitespaces: 1\n",
            "  normalization_rule_tsv: \n",
            "}\n",
            "denormalizer_spec {}\n",
            "trainer_interface.cc(329) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
            "trainer_interface.cc(178) LOG(INFO) Loading corpus: data/4k/bpe/bpe.train\n",
            "trainer_interface.cc(356) LOG(WARNING) Found too long line (5919 > 4192).\n",
            "trainer_interface.cc(358) LOG(WARNING) Too long lines are skipped in the training.\n",
            "trainer_interface.cc(359) LOG(WARNING) The maximum length can be changed with --max_sentence_length=<size> flag.\n",
            "trainer_interface.cc(140) LOG(INFO) Loaded 1000000 lines\n",
            "trainer_interface.cc(140) LOG(INFO) Loaded 2000000 lines\n",
            "trainer_interface.cc(140) LOG(INFO) Loaded 3000000 lines\n",
            "trainer_interface.cc(140) LOG(INFO) Loaded 4000000 lines\n",
            "trainer_interface.cc(140) LOG(INFO) Loaded 5000000 lines\n",
            "trainer_interface.cc(117) LOG(WARNING) Too many sentences are loaded! (5416502), which may slow down training.\n",
            "trainer_interface.cc(119) LOG(WARNING) Consider using --input_sentence_size=<size> and --shuffle_input_sentence=true.\n",
            "trainer_interface.cc(122) LOG(WARNING) They allow to randomly sample <size> sentences from the entire corpus.\n",
            "trainer_interface.cc(385) LOG(INFO) Loaded all 5416502 sentences\n",
            "trainer_interface.cc(391) LOG(INFO) Skipped 4 too long sentences.\n",
            "normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.\n",
            "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <unk>\n",
            "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <s>\n",
            "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: </s>\n",
            "trainer_interface.cc(405) LOG(INFO) Normalizing sentences...\n",
            "trainer_interface.cc(466) LOG(INFO) all chars count=102821715\n",
            "trainer_interface.cc(477) LOG(INFO) Done: 99.5003% characters are covered.\n",
            "trainer_interface.cc(487) LOG(INFO) Alphabet size=953\n",
            "trainer_interface.cc(488) LOG(INFO) Final character coverage=0.995003\n",
            "trainer_interface.cc(520) LOG(INFO) Done! preprocessed 5416502 sentences.\n",
            "trainer_interface.cc(526) LOG(INFO) Tokenizing input sentences with whitespace: 5416502\n",
            "trainer_interface.cc(537) LOG(INFO) Done! 1135113\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=2221594 min_freq=676\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=296674 size=20 all=158537 active=14272 piece=렇게\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=191145 size=40 all=163306 active=19041 piece=▁일\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=150655 size=60 all=167800 active=23535 piece=▁예\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=119284 size=80 all=172920 active=28655 piece=▁할\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=97317 size=100 all=178057 active=33792 piece=▁하면\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=96404 min_freq=583\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=81549 size=120 all=182327 active=13120 piece=▁하고\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=69046 size=140 all=186901 active=17694 piece=▁걸\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=61487 size=160 all=191439 active=22232 piece=▁중\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=55801 size=180 all=195492 active=26285 piece=▁누\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=50150 size=200 all=199702 active=30495 piece=▁엄마\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=50113 min_freq=502\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=44817 size=220 all=202888 active=13025 piece=▁그럼\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=41219 size=240 all=206609 active=16746 piece=▁달\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=37111 size=260 all=210869 active=21006 piece=▁처\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=34946 size=280 all=215507 active=25644 piece=▁뭔가\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=32466 size=300 all=218050 active=28187 piece=▁분\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=31997 min_freq=445\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=30162 size=320 all=221101 active=13785 piece=▁놀\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=28324 size=340 all=224762 active=17446 piece=▁치\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=26298 size=360 all=229797 active=22481 piece=▁어떤\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=25043 size=380 all=233432 active=26116 piece=▁매\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=23636 size=400 all=236283 active=28967 piece=▁산\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=23545 min_freq=397\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=22268 size=420 all=239227 active=14526 piece=았어\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=21220 size=440 all=241990 active=17289 piece=▁아까\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=20471 size=460 all=245703 active=21002 piece=수다\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=19506 size=480 all=250307 active=25606 piece=▁술\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=18785 size=500 all=252408 active=27707 piece=▁김\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=18678 min_freq=363\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=17925 size=520 all=255096 active=15126 piece=▁필\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=17446 size=540 all=258189 active=18219 piece=▁별로\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=16659 size=560 all=261597 active=21627 piece=▁딸\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=15779 size=580 all=265543 active=25573 piece=▁언제\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=14879 size=600 all=269186 active=29216 piece=▁말이\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=14822 min_freq=333\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=14412 size=620 all=273630 active=17812 piece=▁설\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=13623 size=640 all=276241 active=20423 piece=▁없고\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=13102 size=660 all=278065 active=22247 piece=▁아침\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=12557 size=680 all=280459 active=24641 piece=▁책\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=12169 size=700 all=282806 active=26988 piece=으네\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=12159 min_freq=311\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=11691 size=720 all=285243 active=16389 piece=이면\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=10994 size=740 all=287323 active=18469 piece=버리\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=10702 size=760 all=290173 active=21319 piece=▁소리\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=10358 size=780 all=292309 active=23455 piece=▁가야\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=9969 size=800 all=295266 active=26412 piece=이니까\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=9956 min_freq=293\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=9643 size=820 all=297532 active=16491 piece=▁알고\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=9316 size=840 all=299966 active=18925 piece=▁면\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=8985 size=860 all=301793 active=20752 piece=▁어멍\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=8719 size=880 all=304265 active=23224 piece=▁끊\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=8530 size=900 all=306283 active=25242 piece=▁녹\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=8525 min_freq=278\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=8306 size=920 all=308776 active=17695 piece=▁신기\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=8069 size=940 all=311669 active=20588 piece=케이\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=7817 size=960 all=314703 active=23622 piece=장이\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=7567 size=980 all=316836 active=25755 piece=한데\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=7434 size=1000 all=319386 active=28305 piece=▁각\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=7431 min_freq=262\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=7268 size=1020 all=321274 active=17771 piece=▁대학\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=7127 size=1040 all=322695 active=19192 piece=▁버스\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=6979 size=1060 all=324498 active=20995 piece=▁그러니깐\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=6872 size=1080 all=325794 active=22291 piece=건데\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=6748 size=1100 all=328291 active=24788 piece=▁높\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=6733 min_freq=251\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=6625 size=1120 all=330121 active=18150 piece=▁너도\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=6510 size=1140 all=331969 active=19998 piece=▁허는\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=6394 size=1160 all=334063 active=22092 piece=▁하더라\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=6242 size=1180 all=335030 active=23059 piece=▁성격\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=6123 size=1200 all=337387 active=25416 piece=▁답\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=6117 min_freq=241\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=6045 size=1220 all=339812 active=19208 piece=년에\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=5918 size=1240 all=342213 active=21609 piece=▁아직도\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=5811 size=1260 all=343668 active=23064 piece=▁있어야\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=5726 size=1280 all=346232 active=25628 piece=▁억\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=5658 size=1300 all=349143 active=28539 piece=▁어린\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=5646 min_freq=229\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=5530 size=1320 all=352226 active=20495 piece=▁상황\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=5430 size=1340 all=355305 active=23574 piece=▁밑에\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=5335 size=1360 all=356659 active=24928 piece=▁운전\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=5234 size=1380 all=358950 active=27219 piece=▁좋을\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=5155 size=1400 all=360300 active=28569 piece=▁기억이\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=5152 min_freq=220\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=5092 size=1420 all=362618 active=20311 piece=아야\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=4992 size=1440 all=364392 active=22085 piece=만히\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=4936 size=1460 all=366163 active=23856 piece=▁브\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=4831 size=1480 all=367560 active=25253 piece=▁깜짝\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=4745 size=1500 all=369193 active=26886 piece=▁새벽\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=4744 min_freq=212\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=4662 size=1520 all=370790 active=19998 piece=▁짓\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=4554 size=1540 all=373223 active=22431 piece=▁튀\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=4464 size=1560 all=374801 active=24009 piece=▁일찍\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=4406 size=1580 all=376954 active=26162 piece=▁것만\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=4344 size=1600 all=379339 active=28547 piece=▁기본\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=4330 min_freq=204\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=4263 size=1620 all=380780 active=20325 piece=▁끌\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=4197 size=1640 all=382976 active=22521 piece=▁법\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=4119 size=1660 all=384333 active=23878 piece=▁제주도는\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=4083 size=1680 all=386118 active=25663 piece=▁바뀌\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=4035 size=1700 all=387922 active=27467 piece=마자\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=4034 min_freq=197\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=3972 size=1720 all=389647 active=21094 piece=▁상태\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=3915 size=1740 all=392200 active=23647 piece=▁큰일\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=3876 size=1760 all=393694 active=25141 piece=지지\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=3828 size=1780 all=396680 active=28127 piece=▁하나씩\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=3780 size=1800 all=398542 active=29989 piece=▁근디\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=3779 min_freq=189\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=3728 size=1820 all=400723 active=22090 piece=▁늙\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=3676 size=1840 all=402657 active=24024 piece=▁생긴\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=3627 size=1860 all=404666 active=26033 piece=▁오름\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=3593 size=1880 all=406113 active=27480 piece=▁오천\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=3553 size=1900 all=407596 active=28963 piece=▁쭉\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=3552 min_freq=183\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=3510 size=1920 all=408842 active=21589 piece=▁푸\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=3452 size=1940 all=410126 active=22873 piece=▁뉴\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=3424 size=1960 all=411931 active=24678 piece=는거라\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=3399 size=1980 all=413522 active=26269 piece=시면\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=3344 size=2000 all=415253 active=28000 piece=▁척\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=3344 min_freq=178\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=3314 size=2020 all=416729 active=22179 piece=▁말씀\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=3282 size=2040 all=418540 active=23990 piece=▁직장\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=3255 size=2060 all=419918 active=25368 piece=길래\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=3224 size=2080 all=421364 active=26814 piece=▁쓰레\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=3188 size=2100 all=423220 active=28670 piece=성이\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=3181 min_freq=172\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=3151 size=2120 all=425237 active=22908 piece=▁향\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=3109 size=2140 all=426332 active=24003 piece=▁다이어\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=3066 size=2160 all=427947 active=25618 piece=▁여기가\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=3041 size=2180 all=428955 active=26626 piece=마씀\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=3003 size=2200 all=431083 active=28754 piece=▁보기\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=3002 min_freq=167\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=2949 size=2220 all=433061 active=23497 piece=▁잔치\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=2905 size=2240 all=435107 active=25543 piece=었고\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=2876 size=2260 all=436760 active=27196 piece=▁수능\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=2847 size=2280 all=439589 active=30025 piece=▁많지\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=2816 size=2300 all=440957 active=31393 piece=봤는데\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=2815 min_freq=162\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=2781 size=2320 all=442004 active=22976 piece=▁바당\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=2750 size=2340 all=443285 active=24257 piece=▁가장\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=2726 size=2360 all=444731 active=25703 piece=▁거면\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=2690 size=2380 all=446767 active=27739 piece=비가\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=2663 size=2400 all=448754 active=29726 piece=▁값\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=2661 min_freq=158\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=2634 size=2420 all=449953 active=23580 piece=▁매우\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=2609 size=2440 all=451074 active=24701 piece=▁감사\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=2591 size=2460 all=452612 active=26239 piece=▁있었던\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=2567 size=2480 all=454279 active=27906 piece=▁구십\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=2540 size=2500 all=455329 active=28956 piece=▁월급\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=2538 min_freq=154\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=2520 size=2520 all=457130 active=24516 piece=▁끝나면\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=2491 size=2540 all=458738 active=26124 piece=▁펜\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=2475 size=2560 all=460518 active=27904 piece=▁세상에\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=2446 size=2580 all=462060 active=29446 piece=▁머리가\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=2419 size=2600 all=463572 active=30958 piece=▁썩\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=2419 min_freq=150\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=2400 size=2620 all=465230 active=24739 piece=▁의미\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=2378 size=2640 all=466835 active=26344 piece=▁걔도\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=2356 size=2660 all=468692 active=28201 piece=▁요리\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=2323 size=2680 all=470277 active=29786 piece=▁똑똑\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=2313 size=2700 all=471744 active=31253 piece=학과\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=2313 min_freq=146\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=2285 size=2720 all=473776 active=25473 piece=ᄀᆞ\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=2263 size=2740 all=475599 active=27296 piece=▁친한\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=2245 size=2760 all=477302 active=28999 piece=▁어려워\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=2225 size=2780 all=478839 active=30536 piece=▁직원\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=2213 size=2800 all=480505 active=32202 piece=▁죽은\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=2213 min_freq=142\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=2193 size=2820 all=482034 active=25518 piece=▁깊\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=2176 size=2840 all=483068 active=26552 piece=당히\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=2151 size=2860 all=485045 active=28529 piece=▁뜻\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=2132 size=2880 all=486391 active=29875 piece=▁좋은거\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=2113 size=2900 all=487588 active=31072 piece=▁열한\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=2113 min_freq=138\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=2095 size=2920 all=488943 active=25719 piece=▁받아서\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=2069 size=2940 all=489944 active=26720 piece=았지\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=2047 size=2960 all=491779 active=28555 piece=▁게도\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=2023 size=2980 all=492721 active=29497 piece=▁다니면서\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=2012 size=3000 all=494764 active=31540 piece=말고\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=2012 min_freq=135\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=1993 size=3020 all=496493 active=26163 piece=▁집중\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=1974 size=3040 all=497357 active=27027 piece=부분\n",
            "trainer_interface.cc(615) LOG(INFO) Saving model: data/4k/bpe/bpe.model\n",
            "trainer_interface.cc(626) LOG(INFO) Saving vocabs: data/4k/bpe/bpe.vocab\n",
            "normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.\n"
          ]
        }
      ],
      "source": [
        "!python bpe_segment.py --jit jit --vocab_size 4000"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fszOELeFhjtz"
      },
      "source": [
        "# STEP 2. fairseq-prepro"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qVi-t1nth8T6",
        "outputId": "0b16260c-cc35-4c8c-9dc6-f52fa37147f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "/env/python\n",
            "/env/python:/content/gdrive/MyDrive/Tobigs/NLP_conference/fairseq/\n"
          ]
        }
      ],
      "source": [
        "%cd /content\n",
        "\n",
        "! echo $PYTHONPATH\n",
        "\n",
        "import os\n",
        "os.environ['PYTHONPATH'] += \":/content/gdrive/MyDrive/Tobigs/NLP_conference/fairseq/\"\n",
        "\n",
        "! echo $PYTHONPATH"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "42wEljMMiPWU",
        "outputId": "2659dfd7-9c8e-426f-aa33-730ec68e81dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/Tobigs/NLP_conference/jejueo/translation\n"
          ]
        }
      ],
      "source": [
        "cd /content/gdrive/MyDrive/Tobigs/NLP_conference/jejueo/translation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FnNhfNfJfH6M",
        "outputId": "470f62cf-f64b-4eec-9ac4-be25016a748c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-06-07 12:15:34 | INFO | fairseq_cli.preprocess | Namespace(aim_repo=None, aim_run_hash=None, align_suffix=None, alignfile=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, azureml_logging=False, bf16=False, bpe=None, cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='data/4k/ko-je-bin', dict_only=False, empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=False, log_file=None, log_format=None, log_interval=100, lr_scheduler='fixed', memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, on_cpu_convert_precision=False, only_source=False, optimizer=None, padding_factor=8, plasma_path='/tmp/plasma', profile=False, quantization_config_path=None, reset_logging=False, scoring='bleu', seed=1, simul_type=None, source_lang='ko', srcdict='data/4k/bpe/bpe.dict', suppress_crashes=False, target_lang='je', task='translation', tensorboard_logdir=None, testpref='data/4k/bpe/test', tgtdict='data/4k/bpe/bpe.dict', threshold_loss_scale=None, thresholdsrc=0, thresholdtgt=0, tokenizer=None, tpu=False, trainpref='data/4k/bpe/train', use_plasma_view=False, user_dir=None, validpref='data/4k/bpe/dev', wandb_project=None, workers=8)\n",
            "2022-06-07 12:15:36 | INFO | fairseq_cli.preprocess | [ko] Dictionary: 4001 types\n",
            "2022-06-07 12:17:08 | INFO | fairseq_cli.preprocess | [ko] data/4k/bpe/train.ko: 2708253 sents, 26301716 tokens, 0.809% replaced (by <unk>)\n",
            "2022-06-07 12:17:08 | INFO | fairseq_cli.preprocess | [ko] Dictionary: 4001 types\n",
            "2022-06-07 12:17:20 | INFO | fairseq_cli.preprocess | [ko] data/4k/bpe/dev.ko: 323486 sents, 3111491 tokens, 0.796% replaced (by <unk>)\n",
            "2022-06-07 12:17:20 | INFO | fairseq_cli.preprocess | [ko] Dictionary: 4001 types\n",
            "2022-06-07 12:17:33 | INFO | fairseq_cli.preprocess | [ko] data/4k/bpe/test.ko: 323487 sents, 3120440 tokens, 0.782% replaced (by <unk>)\n",
            "2022-06-07 12:17:33 | INFO | fairseq_cli.preprocess | [je] Dictionary: 4001 types\n",
            "2022-06-07 12:19:08 | INFO | fairseq_cli.preprocess | [je] data/4k/bpe/train.je: 2708253 sents, 27176865 tokens, 1.03% replaced (by <unk>)\n",
            "2022-06-07 12:19:08 | INFO | fairseq_cli.preprocess | [je] Dictionary: 4001 types\n",
            "2022-06-07 12:19:20 | INFO | fairseq_cli.preprocess | [je] data/4k/bpe/dev.je: 323486 sents, 3201120 tokens, 0.964% replaced (by <unk>)\n",
            "2022-06-07 12:19:20 | INFO | fairseq_cli.preprocess | [je] Dictionary: 4001 types\n",
            "2022-06-07 12:19:33 | INFO | fairseq_cli.preprocess | [je] data/4k/bpe/test.je: 323487 sents, 3210473 tokens, 0.954% replaced (by <unk>)\n",
            "2022-06-07 12:19:33 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to data/4k/ko-je-bin\n"
          ]
        }
      ],
      "source": [
        "!python prepro.py --src ko --tgt je --vocab_size 4000    # 표준어 -> 제주어"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xg0PTFKVilTN"
      },
      "source": [
        "# STEP 3. fairseq-train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VIGm0c2FfH_G",
        "outputId": "293c68aa-e4fc-45d4-c421-3d8a910ca545"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-06-07 12:20:01 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 1, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': 1e-09, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'train/4k/ko-je-bin/ckpt', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='transformer', activation_dropout=0.0, activation_fn='relu', adam_betas='(0.9, 0.98)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, arch='transformer', attention_dropout=0.0, azureml_logging=False, batch_size=None, batch_size_valid=None, best_checkpoint_metric='loss', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_activations=False, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=0.0, combine_valid_subsets=None, continue_once=None, cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='data/4k/ko-je-bin', data_buffer_size=10, dataset_impl=None, ddp_backend='pytorch_ddp', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path=None, decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=False, decoder_normalize_before=False, decoder_output_dim=512, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=1, distributed_port=-1, distributed_rank=0, distributed_world_size=1, dropout=0.3, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_embed_path=None, encoder_ffn_embed_dim=2048, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=False, encoder_normalize_before=False, eos=2, eval_bleu=False, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=False, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, gen_subset='test', gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, label_smoothing=0.1, layernorm_embedding=False, left_pad_source=True, left_pad_target=False, load_alignments=False, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lr=[0.0005], lr_scheduler='inverse_sqrt', max_epoch=1, max_tokens=4000, max_tokens_valid=4000, max_update=0, max_valid_steps=None, maximize_best_checkpoint_metric=False, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=False, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, not_fsdp_flatten_parameters=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, offload_activations=False, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='train/4k/ko-je-bin/ckpt', save_interval=1, save_interval_updates=0, scoring='bleu', seed=1, sentence_avg=False, shard_id=0, share_all_embeddings=False, share_decoder_input_output_embed=False, simul_type=None, skip_invalid_size_inputs_valid_test=False, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, source_lang=None, stop_min_lr=1e-09, stop_time_hours=0, store_ema=False, suppress_crashes=False, target_lang=None, task='translation', tensorboard_logdir=None, threshold_loss_scale=None, tie_adaptive_weights=False, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, upsample_primary=-1, use_bmuf=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, wandb_project=None, warmup_init_lr=1e-07, warmup_updates=4000, weight_decay=0.0001, write_checkpoints_asynchronously=False, zero_sharding='none'), 'task': {'_name': 'translation', 'data': 'data/4k/ko-je-bin', 'source_lang': None, 'target_lang': None, 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': False, 'eval_bleu_args': '{}', 'eval_bleu_detok': 'space', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': None, 'eval_bleu_print_samples': False}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'label_smoothing': 0.1, 'report_accuracy': False, 'ignore_prefix_size': 0, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0001, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': 1e-07, 'lr': [0.0005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'simul_type': None}\n",
            "2022-06-07 12:20:01 | INFO | fairseq.tasks.translation | [ko] dictionary: 4001 types\n",
            "2022-06-07 12:20:01 | INFO | fairseq.tasks.translation | [je] dictionary: 4001 types\n",
            "2022-06-07 12:20:01 | INFO | fairseq_cli.train | TransformerModel(\n",
            "  (encoder): TransformerEncoderBase(\n",
            "    (dropout_module): FairseqDropout()\n",
            "    (embed_tokens): Embedding(4001, 512, padding_idx=1)\n",
            "    (embed_positions): SinusoidalPositionalEmbedding()\n",
            "    (layers): ModuleList(\n",
            "      (0): TransformerEncoderLayerBase(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (1): TransformerEncoderLayerBase(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (2): TransformerEncoderLayerBase(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (3): TransformerEncoderLayerBase(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (4): TransformerEncoderLayerBase(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (5): TransformerEncoderLayerBase(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (decoder): TransformerDecoderBase(\n",
            "    (dropout_module): FairseqDropout()\n",
            "    (embed_tokens): Embedding(4001, 512, padding_idx=1)\n",
            "    (embed_positions): SinusoidalPositionalEmbedding()\n",
            "    (layers): ModuleList(\n",
            "      (0): TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (1): TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (2): TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (3): TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (4): TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (5): TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "    (output_projection): Linear(in_features=512, out_features=4001, bias=False)\n",
            "  )\n",
            ")\n",
            "2022-06-07 12:20:01 | INFO | fairseq_cli.train | task: TranslationTask\n",
            "2022-06-07 12:20:01 | INFO | fairseq_cli.train | model: TransformerModel\n",
            "2022-06-07 12:20:01 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropyCriterion\n",
            "2022-06-07 12:20:01 | INFO | fairseq_cli.train | num. shared model params: 50,284,032 (num. trained: 50,284,032)\n",
            "2022-06-07 12:20:01 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)\n",
            "2022-06-07 12:20:01 | INFO | fairseq.data.data_utils | loaded 323,486 examples from: data/4k/ko-je-bin/valid.ko-je.ko\n",
            "2022-06-07 12:20:01 | INFO | fairseq.data.data_utils | loaded 323,486 examples from: data/4k/ko-je-bin/valid.ko-je.je\n",
            "2022-06-07 12:20:01 | INFO | fairseq.tasks.translation | data/4k/ko-je-bin valid ko-je 323486 examples\n",
            "2022-06-07 12:20:13 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2022-06-07 12:20:13 | INFO | fairseq.utils | rank   0: capabilities =  7.5  ; total memory = 14.756 GB ; name = Tesla T4                                \n",
            "2022-06-07 12:20:13 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2022-06-07 12:20:13 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)\n",
            "2022-06-07 12:20:13 | INFO | fairseq_cli.train | max tokens per device = 4000 and max sentences per device = None\n",
            "2022-06-07 12:20:13 | INFO | fairseq.trainer | Preparing to load checkpoint train/4k/ko-je-bin/ckpt/checkpoint_last.pt\n",
            "2022-06-07 12:20:13 | INFO | fairseq.trainer | No existing checkpoint found train/4k/ko-je-bin/ckpt/checkpoint_last.pt\n",
            "2022-06-07 12:20:13 | INFO | fairseq.trainer | loading train data for epoch 1\n",
            "2022-06-07 12:20:13 | INFO | fairseq.data.data_utils | loaded 2,708,253 examples from: data/4k/ko-je-bin/train.ko-je.ko\n",
            "2022-06-07 12:20:13 | INFO | fairseq.data.data_utils | loaded 2,708,253 examples from: data/4k/ko-je-bin/train.ko-je.je\n",
            "2022-06-07 12:20:13 | INFO | fairseq.tasks.translation | data/4k/ko-je-bin train ko-je 2708253 examples\n",
            "2022-06-07 12:20:14 | WARNING | fairseq.tasks.fairseq_task | 3 samples have invalid sizes and will be skipped, max_positions=(1024, 1024), first few sample ids=[115382, 148575, 60577]\n",
            "2022-06-07 12:20:14 | INFO | fairseq.trainer | NOTE: your device may support faster training with --fp16 or --amp\n",
            "2022-06-07 12:20:14 | INFO | fairseq.data.iterators | grouped total_num_itrs = 6979\n",
            "epoch 001:   0% 0/6979 [00:00<?, ?it/s]2022-06-07 12:20:14 | INFO | fairseq.trainer | begin training epoch 1\n",
            "2022-06-07 12:20:14 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "/content/gdrive/MyDrive/Tobigs/NLP_conference/fairseq/fairseq/utils.py:375: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library\n",
            "  \"amp_C fused kernels unavailable, disabling multi_tensor_l2norm; \"\n",
            "epoch 001: 100% 6978/6979 [44:25<00:00,  2.56it/s, loss=2.662, nll_loss=1.197, ppl=2.29, wps=10201.9, ups=2.65, wpb=3856.9, bsz=385, num_updates=6900, lr=0.000380693, gnorm=1.044, train_wall=38, gb_free=12.5, wall=2637]2022-06-07 13:04:40 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:   0% 0/837 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:   0% 1/837 [00:00<05:17,  2.63it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:   0% 2/837 [00:00<03:12,  4.34it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:   0% 3/837 [00:00<02:33,  5.45it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:   0% 4/837 [00:00<02:14,  6.20it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:   1% 5/837 [00:00<02:03,  6.75it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:   1% 6/837 [00:01<01:57,  7.10it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:   1% 7/837 [00:01<01:56,  7.11it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:   1% 8/837 [00:01<01:55,  7.15it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:   1% 9/837 [00:01<01:52,  7.36it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:   1% 11/837 [00:01<01:34,  8.74it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:   2% 13/837 [00:01<01:31,  9.02it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:   2% 14/837 [00:01<01:34,  8.74it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:   2% 15/837 [00:02<01:36,  8.53it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:   2% 16/837 [00:02<01:39,  8.23it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:   2% 17/837 [00:02<01:41,  8.04it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:   2% 18/837 [00:02<01:43,  7.95it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:   2% 19/837 [00:02<01:43,  7.92it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:   2% 20/837 [00:02<01:43,  7.91it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:   3% 21/837 [00:02<01:43,  7.91it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:   3% 22/837 [00:02<01:42,  7.92it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:   3% 23/837 [00:03<01:43,  7.85it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:   3% 24/837 [00:03<01:44,  7.80it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:   3% 25/837 [00:03<01:45,  7.71it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:   3% 26/837 [00:03<01:44,  7.76it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:   3% 27/837 [00:03<01:37,  8.30it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:   3% 28/837 [00:03<01:35,  8.43it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:   4% 30/837 [00:03<01:27,  9.28it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:   4% 31/837 [00:04<01:31,  8.82it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:   4% 32/837 [00:04<01:34,  8.48it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:   4% 33/837 [00:04<01:36,  8.29it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:   4% 34/837 [00:04<01:39,  8.09it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:   4% 35/837 [00:04<01:40,  8.00it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:   4% 36/837 [00:04<01:41,  7.89it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:   4% 37/837 [00:04<01:41,  7.87it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:   5% 38/837 [00:04<01:41,  7.87it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:   5% 39/837 [00:05<01:42,  7.79it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:   5% 40/837 [00:05<01:42,  7.76it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:   5% 41/837 [00:05<01:42,  7.73it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:   5% 42/837 [00:05<01:42,  7.74it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:   5% 43/837 [00:05<01:41,  7.80it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:   5% 44/837 [00:05<01:41,  7.81it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:   5% 45/837 [00:05<01:41,  7.82it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:   5% 46/837 [00:05<01:41,  7.80it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:   6% 47/837 [00:06<01:41,  7.77it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:   6% 48/837 [00:06<01:41,  7.75it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:   6% 49/837 [00:06<01:42,  7.72it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:   6% 50/837 [00:06<01:39,  7.94it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:   6% 51/837 [00:06<01:36,  8.12it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:   6% 52/837 [00:06<01:33,  8.39it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:   6% 54/837 [00:06<01:23,  9.33it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:   7% 55/837 [00:07<01:28,  8.86it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:   7% 56/837 [00:07<01:31,  8.56it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:   7% 57/837 [00:07<01:34,  8.27it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:   7% 58/837 [00:07<01:36,  8.11it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:   7% 59/837 [00:07<01:37,  7.99it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:   7% 60/837 [00:07<01:37,  7.94it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:   7% 61/837 [00:07<01:37,  7.92it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:   7% 62/837 [00:07<01:38,  7.86it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:   8% 63/837 [00:08<01:39,  7.79it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:   8% 64/837 [00:08<01:39,  7.77it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:   8% 65/837 [00:08<01:40,  7.72it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:   8% 66/837 [00:08<01:39,  7.73it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:   8% 67/837 [00:08<01:39,  7.72it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:   8% 68/837 [00:08<01:39,  7.73it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:   8% 69/837 [00:08<01:38,  7.76it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:   8% 70/837 [00:08<01:39,  7.74it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:   8% 71/837 [00:09<01:39,  7.73it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:   9% 72/837 [00:09<01:39,  7.67it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:   9% 73/837 [00:09<01:39,  7.66it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:   9% 74/837 [00:09<01:39,  7.65it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:   9% 75/837 [00:09<01:39,  7.69it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:   9% 76/837 [00:09<01:38,  7.74it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:   9% 77/837 [00:09<01:38,  7.71it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:   9% 78/837 [00:09<01:38,  7.73it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:   9% 79/837 [00:10<01:37,  7.76it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  10% 80/837 [00:10<01:38,  7.71it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  10% 81/837 [00:10<01:36,  7.87it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  10% 82/837 [00:10<01:34,  7.97it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  10% 83/837 [00:10<01:33,  8.08it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  10% 84/837 [00:10<01:30,  8.30it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  10% 85/837 [00:10<01:29,  8.43it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  10% 87/837 [00:11<01:27,  8.61it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  11% 88/837 [00:11<01:29,  8.36it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  11% 89/837 [00:11<01:31,  8.19it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  11% 90/837 [00:11<01:32,  8.04it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  11% 91/837 [00:11<01:34,  7.93it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  11% 92/837 [00:11<01:34,  7.88it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  11% 93/837 [00:11<01:35,  7.80it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  11% 94/837 [00:11<01:35,  7.78it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  11% 95/837 [00:12<01:35,  7.80it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  11% 96/837 [00:12<01:34,  7.80it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  12% 97/837 [00:12<01:34,  7.81it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  12% 98/837 [00:12<01:35,  7.76it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  12% 99/837 [00:12<01:35,  7.73it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  12% 100/837 [00:12<01:35,  7.73it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  12% 101/837 [00:12<01:35,  7.68it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  12% 102/837 [00:13<01:35,  7.72it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  12% 103/837 [00:13<01:34,  7.77it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  12% 104/837 [00:13<01:34,  7.74it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  13% 105/837 [00:13<01:34,  7.72it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  13% 106/837 [00:13<01:35,  7.68it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  13% 107/837 [00:13<01:35,  7.68it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  13% 108/837 [00:13<01:34,  7.69it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  13% 109/837 [00:13<01:34,  7.68it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  13% 110/837 [00:14<01:34,  7.72it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  13% 111/837 [00:14<01:33,  7.73it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  13% 112/837 [00:14<01:33,  7.74it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  14% 113/837 [00:14<01:33,  7.76it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  14% 114/837 [00:14<01:33,  7.71it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  14% 115/837 [00:14<01:33,  7.70it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  14% 116/837 [00:14<01:33,  7.71it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  14% 117/837 [00:14<01:33,  7.71it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  14% 118/837 [00:15<01:32,  7.75it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  14% 119/837 [00:15<01:31,  7.84it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  14% 120/837 [00:15<01:29,  7.98it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  14% 121/837 [00:15<01:29,  8.02it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  15% 122/837 [00:15<01:28,  8.05it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  15% 123/837 [00:15<01:28,  8.09it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  15% 124/837 [00:15<01:26,  8.21it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  15% 125/837 [00:15<01:25,  8.36it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  15% 127/837 [00:16<01:21,  8.73it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  15% 128/837 [00:16<01:23,  8.46it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  15% 129/837 [00:16<01:25,  8.25it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  16% 130/837 [00:16<01:27,  8.08it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  16% 131/837 [00:16<01:28,  7.99it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  16% 132/837 [00:16<01:29,  7.87it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  16% 133/837 [00:16<01:30,  7.81it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  16% 134/837 [00:17<01:30,  7.75it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  16% 135/837 [00:17<01:30,  7.73it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  16% 136/837 [00:17<01:30,  7.72it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  16% 137/837 [00:17<01:30,  7.70it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  16% 138/837 [00:17<01:30,  7.72it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  17% 139/837 [00:17<01:30,  7.68it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  17% 140/837 [00:17<01:30,  7.74it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  17% 141/837 [00:17<01:29,  7.77it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  17% 142/837 [00:18<01:29,  7.73it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  17% 143/837 [00:18<01:29,  7.73it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  17% 144/837 [00:18<01:30,  7.70it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  17% 145/837 [00:18<01:29,  7.71it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  17% 146/837 [00:18<01:29,  7.72it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  18% 147/837 [00:18<01:29,  7.67it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  18% 148/837 [00:18<01:29,  7.68it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  18% 149/837 [00:19<01:29,  7.66it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  18% 150/837 [00:19<01:29,  7.69it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  18% 151/837 [00:19<01:29,  7.68it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  18% 152/837 [00:19<01:29,  7.69it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  18% 153/837 [00:19<01:28,  7.72it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  18% 154/837 [00:19<01:28,  7.69it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  19% 155/837 [00:19<01:28,  7.70it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  19% 156/837 [00:19<01:28,  7.66it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  19% 157/837 [00:20<01:28,  7.67it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  19% 158/837 [00:20<01:28,  7.67it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  19% 159/837 [00:20<01:28,  7.67it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  19% 160/837 [00:20<01:28,  7.68it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  19% 161/837 [00:20<01:28,  7.68it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  19% 162/837 [00:20<01:27,  7.73it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  19% 163/837 [00:20<01:26,  7.83it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  20% 164/837 [00:20<01:25,  7.90it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  20% 165/837 [00:21<01:24,  7.99it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  20% 166/837 [00:21<01:23,  8.02it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  20% 167/837 [00:21<01:23,  8.06it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  20% 168/837 [00:21<01:22,  8.11it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  20% 169/837 [00:21<01:21,  8.20it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  20% 170/837 [00:21<01:20,  8.29it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  20% 171/837 [00:21<01:19,  8.39it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  21% 173/837 [00:22<01:16,  8.69it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  21% 174/837 [00:22<01:18,  8.41it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  21% 175/837 [00:22<01:21,  8.17it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  21% 176/837 [00:22<01:22,  8.04it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  21% 177/837 [00:22<01:23,  7.94it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  21% 178/837 [00:22<01:23,  7.88it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  21% 179/837 [00:22<01:23,  7.83it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  22% 180/837 [00:22<01:24,  7.75it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  22% 181/837 [00:23<01:24,  7.76it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  22% 182/837 [00:23<01:25,  7.70it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  22% 183/837 [00:23<01:24,  7.71it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  22% 184/837 [00:23<01:24,  7.72it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  22% 185/837 [00:23<01:24,  7.73it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  22% 186/837 [00:23<01:23,  7.76it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  22% 187/837 [00:23<01:23,  7.78it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  22% 188/837 [00:23<01:23,  7.73it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  23% 189/837 [00:24<01:23,  7.75it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  23% 190/837 [00:24<01:24,  7.69it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  23% 191/837 [00:24<01:23,  7.73it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  23% 192/837 [00:24<01:23,  7.72it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  23% 193/837 [00:24<01:23,  7.72it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  23% 194/837 [00:24<01:22,  7.76it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  23% 195/837 [00:24<01:23,  7.72it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  23% 196/837 [00:24<01:23,  7.69it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  24% 197/837 [00:25<01:22,  7.74it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  24% 198/837 [00:25<01:22,  7.71it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  24% 199/837 [00:25<01:22,  7.74it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  24% 200/837 [00:25<01:22,  7.70it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  24% 201/837 [00:25<01:22,  7.73it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  24% 202/837 [00:25<01:21,  7.78it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  24% 203/837 [00:25<01:21,  7.75it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  24% 204/837 [00:26<01:22,  7.72it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  24% 205/837 [00:26<01:21,  7.73it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  25% 206/837 [00:26<01:21,  7.71it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  25% 207/837 [00:26<01:21,  7.72it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  25% 208/837 [00:26<01:21,  7.68it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  25% 209/837 [00:26<01:21,  7.70it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  25% 210/837 [00:26<01:20,  7.76it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  25% 211/837 [00:26<01:19,  7.85it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  25% 212/837 [00:27<01:18,  7.93it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  25% 213/837 [00:27<01:17,  8.00it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  26% 214/837 [00:27<01:17,  8.02it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  26% 215/837 [00:27<01:17,  8.06it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  26% 216/837 [00:27<01:16,  8.10it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  26% 217/837 [00:27<01:16,  8.11it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  26% 218/837 [00:27<01:14,  8.28it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  26% 219/837 [00:27<01:13,  8.37it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  26% 220/837 [00:28<01:13,  8.38it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  26% 221/837 [00:28<01:12,  8.50it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  27% 222/837 [00:28<01:10,  8.76it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  27% 223/837 [00:28<01:11,  8.62it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  27% 224/837 [00:28<01:13,  8.36it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  27% 225/837 [00:28<01:15,  8.08it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  27% 226/837 [00:28<01:16,  7.98it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  27% 227/837 [00:28<01:17,  7.87it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  27% 228/837 [00:28<01:17,  7.83it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  27% 229/837 [00:29<01:18,  7.77it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  27% 230/837 [00:29<01:18,  7.71it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  28% 231/837 [00:29<01:18,  7.69it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  28% 232/837 [00:29<01:18,  7.67it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  28% 233/837 [00:29<01:18,  7.68it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  28% 234/837 [00:29<01:18,  7.67it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  28% 235/837 [00:29<01:18,  7.67it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  28% 236/837 [00:30<01:18,  7.64it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  28% 237/837 [00:30<01:18,  7.64it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  28% 238/837 [00:30<01:18,  7.61it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  29% 239/837 [00:30<01:18,  7.64it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  29% 240/837 [00:30<01:18,  7.60it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  29% 241/837 [00:30<01:17,  7.65it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  29% 242/837 [00:30<01:17,  7.63it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  29% 243/837 [00:30<01:17,  7.65it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  29% 244/837 [00:31<01:17,  7.64it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  29% 245/837 [00:31<01:17,  7.63it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  29% 246/837 [00:31<01:17,  7.64it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  30% 247/837 [00:31<01:17,  7.63it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  30% 248/837 [00:31<01:17,  7.65it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  30% 249/837 [00:31<01:16,  7.65it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  30% 250/837 [00:31<01:16,  7.65it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  30% 251/837 [00:32<01:16,  7.62it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  30% 252/837 [00:32<01:16,  7.63it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  30% 253/837 [00:32<01:16,  7.61it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  30% 254/837 [00:32<01:16,  7.61it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  30% 255/837 [00:32<01:16,  7.60it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  31% 256/837 [00:32<01:15,  7.65it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  31% 257/837 [00:32<01:16,  7.61it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  31% 258/837 [00:32<01:15,  7.66it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  31% 259/837 [00:33<01:15,  7.65it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  31% 260/837 [00:33<01:15,  7.64it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  31% 261/837 [00:33<01:15,  7.63it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  31% 262/837 [00:33<01:15,  7.62it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  31% 263/837 [00:33<01:14,  7.73it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  32% 264/837 [00:33<01:13,  7.77it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  32% 265/837 [00:33<01:13,  7.81it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  32% 266/837 [00:33<01:12,  7.89it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  32% 267/837 [00:34<01:11,  7.95it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  32% 268/837 [00:34<01:11,  7.97it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  32% 269/837 [00:34<01:11,  7.93it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  32% 270/837 [00:34<01:10,  8.03it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  32% 271/837 [00:34<01:09,  8.09it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  32% 272/837 [00:34<01:09,  8.12it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  33% 273/837 [00:34<01:08,  8.25it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  33% 274/837 [00:34<01:07,  8.39it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  33% 276/837 [00:35<00:59,  9.47it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  33% 277/837 [00:35<01:01,  9.09it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  33% 278/837 [00:35<01:04,  8.69it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  33% 279/837 [00:35<01:06,  8.33it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  33% 280/837 [00:35<01:08,  8.17it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  34% 281/837 [00:35<01:09,  7.96it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  34% 282/837 [00:35<01:10,  7.88it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  34% 283/837 [00:36<01:11,  7.79it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  34% 284/837 [00:36<01:11,  7.75it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  34% 285/837 [00:36<01:11,  7.70it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  34% 286/837 [00:36<01:11,  7.71it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  34% 287/837 [00:36<01:11,  7.72it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  34% 288/837 [00:36<01:11,  7.67it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  35% 289/837 [00:36<01:11,  7.68it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  35% 290/837 [00:36<01:11,  7.68it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  35% 291/837 [00:37<01:10,  7.71it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  35% 292/837 [00:37<01:11,  7.65it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  35% 293/837 [00:37<01:11,  7.65it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  35% 294/837 [00:37<01:11,  7.63it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  35% 295/837 [00:37<01:10,  7.65it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  35% 296/837 [00:37<01:10,  7.63it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  35% 297/837 [00:37<01:10,  7.63it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  36% 298/837 [00:37<01:10,  7.65it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  36% 299/837 [00:38<01:10,  7.65it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  36% 300/837 [00:38<01:09,  7.68it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  36% 301/837 [00:38<01:10,  7.66it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  36% 302/837 [00:38<01:09,  7.68it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  36% 303/837 [00:38<01:09,  7.65it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  36% 304/837 [00:38<01:09,  7.66it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  36% 305/837 [00:38<01:09,  7.62it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  37% 306/837 [00:39<01:09,  7.63it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  37% 307/837 [00:39<01:09,  7.61it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  37% 308/837 [00:39<01:09,  7.63it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  37% 309/837 [00:39<01:09,  7.61it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  37% 310/837 [00:39<01:09,  7.63it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  37% 311/837 [00:39<01:08,  7.63it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  37% 312/837 [00:39<01:08,  7.63it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  37% 313/837 [00:39<01:08,  7.66it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  38% 314/837 [00:40<01:08,  7.66it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  38% 315/837 [00:40<01:08,  7.67it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  38% 316/837 [00:40<01:07,  7.75it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  38% 317/837 [00:40<01:06,  7.82it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  38% 318/837 [00:40<01:05,  7.89it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  38% 319/837 [00:40<01:05,  7.93it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  38% 320/837 [00:40<01:05,  7.95it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  38% 321/837 [00:40<01:04,  7.95it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  38% 322/837 [00:41<01:04,  7.93it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  39% 323/837 [00:41<01:04,  7.92it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  39% 324/837 [00:41<01:03,  8.04it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  39% 325/837 [00:41<01:03,  8.11it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  39% 326/837 [00:41<01:02,  8.18it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  39% 327/837 [00:41<01:01,  8.30it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  39% 328/837 [00:41<00:58,  8.63it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  39% 329/837 [00:41<00:57,  8.91it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  39% 330/837 [00:42<00:58,  8.61it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  40% 331/837 [00:42<01:00,  8.32it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  40% 332/837 [00:42<01:02,  8.09it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  40% 333/837 [00:42<01:03,  7.95it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  40% 334/837 [00:42<01:04,  7.83it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  40% 335/837 [00:42<01:04,  7.79it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  40% 336/837 [00:42<01:05,  7.70it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  40% 337/837 [00:42<01:05,  7.67it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  40% 338/837 [00:43<01:05,  7.66it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  41% 339/837 [00:43<01:05,  7.65it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  41% 340/837 [00:43<01:05,  7.62it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  41% 341/837 [00:43<01:05,  7.63it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  41% 342/837 [00:43<01:05,  7.61it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  41% 343/837 [00:43<01:04,  7.61it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  41% 344/837 [00:43<01:04,  7.59it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  41% 345/837 [00:43<01:04,  7.61it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  41% 346/837 [00:44<01:04,  7.57it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  41% 347/837 [00:44<01:04,  7.60it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  42% 348/837 [00:44<01:04,  7.58it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  42% 349/837 [00:44<01:04,  7.60it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  42% 350/837 [00:44<01:04,  7.59it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  42% 351/837 [00:44<01:03,  7.60it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  42% 352/837 [00:44<01:03,  7.59it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  42% 353/837 [00:45<01:03,  7.60it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  42% 354/837 [00:45<01:03,  7.58it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  42% 355/837 [00:45<01:03,  7.60it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  43% 356/837 [00:45<01:03,  7.58it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  43% 357/837 [00:45<01:03,  7.59it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  43% 358/837 [00:45<01:03,  7.58it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  43% 359/837 [00:45<01:03,  7.58it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  43% 360/837 [00:45<01:02,  7.58it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  43% 361/837 [00:46<01:02,  7.59it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  43% 362/837 [00:46<01:02,  7.60it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  43% 363/837 [00:46<01:02,  7.59it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  43% 364/837 [00:46<01:02,  7.58it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  44% 365/837 [00:46<01:02,  7.61it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  44% 366/837 [00:46<01:02,  7.58it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  44% 367/837 [00:46<01:01,  7.62it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  44% 368/837 [00:47<01:01,  7.67it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  44% 369/837 [00:47<01:00,  7.75it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  44% 370/837 [00:47<00:59,  7.84it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  44% 371/837 [00:47<00:59,  7.89it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  44% 372/837 [00:47<00:58,  7.89it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  45% 373/837 [00:47<00:58,  7.90it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  45% 374/837 [00:47<00:58,  7.90it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  45% 375/837 [00:47<00:58,  7.95it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  45% 376/837 [00:48<00:57,  8.01it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  45% 377/837 [00:48<00:57,  8.06it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  45% 378/837 [00:48<00:56,  8.07it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  45% 379/837 [00:48<00:56,  8.15it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  45% 380/837 [00:48<00:55,  8.21it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  46% 381/837 [00:48<00:54,  8.44it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  46% 382/837 [00:48<00:52,  8.61it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  46% 383/837 [00:48<00:53,  8.44it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  46% 384/837 [00:48<00:55,  8.15it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  46% 385/837 [00:49<00:56,  8.00it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  46% 386/837 [00:49<00:57,  7.89it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  46% 387/837 [00:49<00:57,  7.81it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  46% 388/837 [00:49<00:58,  7.74it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  46% 389/837 [00:49<00:58,  7.70it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  47% 390/837 [00:49<00:58,  7.64it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  47% 391/837 [00:49<00:58,  7.64it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  47% 392/837 [00:50<00:58,  7.62it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  47% 393/837 [00:50<00:58,  7.64it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  47% 394/837 [00:50<00:58,  7.62it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  47% 395/837 [00:50<00:58,  7.62it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  47% 396/837 [00:50<00:58,  7.60it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  47% 397/837 [00:50<00:57,  7.60it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  48% 398/837 [00:50<00:57,  7.59it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  48% 399/837 [00:50<00:57,  7.60it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  48% 400/837 [00:51<00:57,  7.57it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  48% 401/837 [00:51<00:57,  7.61it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  48% 402/837 [00:51<00:57,  7.59it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  48% 403/837 [00:51<00:57,  7.61it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  48% 404/837 [00:51<00:57,  7.58it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  48% 405/837 [00:51<00:56,  7.59it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  49% 406/837 [00:51<00:56,  7.59it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  49% 407/837 [00:52<00:56,  7.60it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  49% 408/837 [00:52<00:56,  7.59it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  49% 409/837 [00:52<00:56,  7.62it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  49% 410/837 [00:52<00:56,  7.62it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  49% 411/837 [00:52<00:56,  7.59it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  49% 412/837 [00:52<00:56,  7.59it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  49% 413/837 [00:52<00:55,  7.59it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  49% 414/837 [00:52<00:55,  7.56it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  50% 415/837 [00:53<00:55,  7.59it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  50% 416/837 [00:53<00:55,  7.59it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  50% 417/837 [00:53<00:55,  7.61it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  50% 418/837 [00:53<00:55,  7.61it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  50% 419/837 [00:53<00:54,  7.74it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  50% 420/837 [00:53<00:53,  7.75it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  50% 421/837 [00:53<00:53,  7.80it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  50% 422/837 [00:53<00:53,  7.79it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  51% 423/837 [00:54<00:52,  7.84it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  51% 424/837 [00:54<00:52,  7.90it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  51% 425/837 [00:54<00:52,  7.91it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  51% 426/837 [00:54<00:51,  7.90it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  51% 427/837 [00:54<00:51,  8.00it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  51% 428/837 [00:54<00:50,  8.06it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  51% 429/837 [00:54<00:50,  8.11it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  51% 430/837 [00:54<00:50,  8.13it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  51% 431/837 [00:55<00:49,  8.22it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  52% 432/837 [00:55<00:48,  8.32it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  52% 433/837 [00:55<00:46,  8.60it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  52% 434/837 [00:55<00:46,  8.75it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  52% 435/837 [00:55<00:47,  8.52it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  52% 436/837 [00:55<00:48,  8.22it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  52% 437/837 [00:55<00:49,  8.02it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  52% 438/837 [00:55<00:50,  7.88it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  52% 439/837 [00:56<00:51,  7.79it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  53% 440/837 [00:56<00:51,  7.75it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  53% 441/837 [00:56<00:51,  7.69it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  53% 442/837 [00:56<00:51,  7.66it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  53% 443/837 [00:56<00:51,  7.62it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  53% 444/837 [00:56<00:51,  7.58it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  53% 445/837 [00:56<00:51,  7.59it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  53% 446/837 [00:56<00:51,  7.57it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  53% 447/837 [00:57<00:51,  7.60it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  54% 448/837 [00:57<00:51,  7.57it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  54% 449/837 [00:57<00:51,  7.56it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  54% 450/837 [00:57<00:51,  7.57it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  54% 451/837 [00:57<00:50,  7.59it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  54% 452/837 [00:57<00:50,  7.59it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  54% 453/837 [00:57<00:50,  7.61it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  54% 454/837 [00:58<00:50,  7.60it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  54% 455/837 [00:58<00:50,  7.59it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  54% 456/837 [00:58<00:50,  7.59it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  55% 457/837 [00:58<00:49,  7.61it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  55% 458/837 [00:58<00:49,  7.59it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  55% 459/837 [00:58<00:49,  7.60it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  55% 460/837 [00:58<00:49,  7.59it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  55% 461/837 [00:58<00:49,  7.61it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  55% 462/837 [00:59<00:49,  7.58it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  55% 463/837 [00:59<00:49,  7.59it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  55% 464/837 [00:59<00:49,  7.58it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  56% 465/837 [00:59<00:49,  7.59it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  56% 466/837 [00:59<00:48,  7.60it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  56% 467/837 [00:59<00:48,  7.62it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  56% 468/837 [00:59<00:48,  7.59it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  56% 469/837 [00:59<00:47,  7.69it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  56% 470/837 [01:00<00:47,  7.70it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  56% 471/837 [01:00<00:47,  7.75it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  56% 472/837 [01:00<00:46,  7.81it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  57% 473/837 [01:00<00:46,  7.87it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  57% 474/837 [01:00<00:46,  7.86it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  57% 475/837 [01:00<00:45,  7.90it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  57% 476/837 [01:00<00:45,  7.96it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  57% 477/837 [01:01<00:45,  7.99it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  57% 478/837 [01:01<00:44,  8.02it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  57% 479/837 [01:01<00:44,  8.06it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  57% 480/837 [01:01<00:44,  8.09it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  57% 481/837 [01:01<00:43,  8.19it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  58% 482/837 [01:01<00:41,  8.55it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  58% 483/837 [01:01<00:42,  8.30it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  58% 484/837 [01:01<00:43,  8.08it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  58% 485/837 [01:01<00:44,  7.94it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  58% 486/837 [01:02<00:44,  7.83it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  58% 487/837 [01:02<00:45,  7.77it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  58% 488/837 [01:02<00:45,  7.74it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  58% 489/837 [01:02<00:45,  7.70it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  59% 490/837 [01:02<00:45,  7.67it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  59% 491/837 [01:02<00:45,  7.68it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  59% 492/837 [01:02<00:45,  7.66it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  59% 493/837 [01:03<00:45,  7.64it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  59% 494/837 [01:03<00:44,  7.62it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  59% 495/837 [01:03<00:44,  7.62it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  59% 496/837 [01:03<00:44,  7.62it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  59% 497/837 [01:03<00:44,  7.64it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  59% 498/837 [01:03<00:44,  7.61it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  60% 499/837 [01:03<00:44,  7.61it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  60% 500/837 [01:03<00:44,  7.60it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  60% 501/837 [01:04<00:44,  7.61it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  60% 502/837 [01:04<00:44,  7.59it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  60% 503/837 [01:04<00:43,  7.60it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  60% 504/837 [01:04<00:43,  7.58it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  60% 505/837 [01:04<00:43,  7.59it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  60% 506/837 [01:04<00:43,  7.58it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  61% 507/837 [01:04<00:43,  7.61it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  61% 508/837 [01:05<00:43,  7.60it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  61% 509/837 [01:05<00:42,  7.63it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  61% 510/837 [01:05<00:42,  7.63it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  61% 511/837 [01:05<00:42,  7.64it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  61% 512/837 [01:05<00:42,  7.58it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  61% 513/837 [01:05<00:42,  7.60it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  61% 514/837 [01:05<00:42,  7.60it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  62% 515/837 [01:05<00:42,  7.66it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  62% 516/837 [01:06<00:41,  7.69it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  62% 517/837 [01:06<00:41,  7.74it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  62% 518/837 [01:06<00:41,  7.76it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  62% 519/837 [01:06<00:40,  7.77it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  62% 520/837 [01:06<00:40,  7.75it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  62% 521/837 [01:06<00:40,  7.77it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  62% 522/837 [01:06<00:40,  7.79it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  62% 523/837 [01:06<00:39,  7.87it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  63% 524/837 [01:07<00:39,  7.91it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  63% 525/837 [01:07<00:39,  7.98it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  63% 526/837 [01:07<00:38,  8.14it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  63% 527/837 [01:07<00:36,  8.50it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  63% 528/837 [01:07<00:37,  8.27it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  63% 529/837 [01:07<00:38,  7.98it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  63% 530/837 [01:07<00:38,  7.88it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  63% 531/837 [01:07<00:39,  7.77it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  64% 532/837 [01:08<00:39,  7.72it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  64% 533/837 [01:08<00:39,  7.67it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  64% 534/837 [01:08<00:39,  7.64it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  64% 535/837 [01:08<00:39,  7.57it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  64% 536/837 [01:08<00:40,  7.49it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  64% 537/837 [01:08<00:39,  7.53it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  64% 538/837 [01:08<00:39,  7.51it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  64% 539/837 [01:09<00:39,  7.52it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  65% 540/837 [01:09<00:39,  7.52it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  65% 541/837 [01:09<00:39,  7.48it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  65% 542/837 [01:09<00:39,  7.51it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  65% 543/837 [01:09<00:39,  7.46it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  65% 544/837 [01:09<00:39,  7.46it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  65% 545/837 [01:09<00:38,  7.50it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  65% 546/837 [01:09<00:38,  7.49it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  65% 547/837 [01:10<00:38,  7.52it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  65% 548/837 [01:10<00:38,  7.52it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  66% 549/837 [01:10<00:38,  7.55it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  66% 550/837 [01:10<00:38,  7.52it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  66% 551/837 [01:10<00:38,  7.52it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  66% 552/837 [01:10<00:37,  7.51it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  66% 553/837 [01:10<00:37,  7.49it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  66% 554/837 [01:11<00:37,  7.51it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  66% 555/837 [01:11<00:37,  7.50it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  66% 556/837 [01:11<00:36,  7.61it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  67% 557/837 [01:11<00:36,  7.64it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  67% 558/837 [01:11<00:36,  7.69it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  67% 559/837 [01:11<00:36,  7.71it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  67% 560/837 [01:11<00:35,  7.70it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  67% 561/837 [01:11<00:35,  7.72it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  67% 562/837 [01:12<00:35,  7.71it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  67% 563/837 [01:12<00:35,  7.77it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  67% 564/837 [01:12<00:34,  7.84it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  68% 565/837 [01:12<00:34,  7.92it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  68% 566/837 [01:12<00:33,  7.99it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  68% 567/837 [01:12<00:33,  8.13it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  68% 568/837 [01:12<00:31,  8.43it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  68% 569/837 [01:12<00:32,  8.20it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  68% 570/837 [01:13<00:33,  7.98it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  68% 571/837 [01:13<00:34,  7.81it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  68% 572/837 [01:13<00:34,  7.76it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  68% 573/837 [01:13<00:34,  7.70it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  69% 574/837 [01:13<00:34,  7.65it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  69% 575/837 [01:13<00:34,  7.61it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  69% 576/837 [01:13<00:34,  7.57it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  69% 577/837 [01:13<00:34,  7.56it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  69% 578/837 [01:14<00:34,  7.51it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  69% 579/837 [01:14<00:34,  7.53it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  69% 580/837 [01:14<00:34,  7.53it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  69% 581/837 [01:14<00:33,  7.55it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  70% 582/837 [01:14<00:33,  7.56it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  70% 583/837 [01:14<00:33,  7.54it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  70% 584/837 [01:14<00:33,  7.51it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  70% 585/837 [01:15<00:33,  7.48it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  70% 586/837 [01:15<00:33,  7.50it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  70% 587/837 [01:15<00:33,  7.50it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  70% 588/837 [01:15<00:33,  7.53it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  70% 589/837 [01:15<00:32,  7.54it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  70% 590/837 [01:15<00:32,  7.55it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  71% 591/837 [01:15<00:32,  7.52it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  71% 592/837 [01:15<00:32,  7.45it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  71% 593/837 [01:16<00:32,  7.49it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  71% 594/837 [01:16<00:32,  7.55it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  71% 595/837 [01:16<00:31,  7.62it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  71% 596/837 [01:16<00:31,  7.63it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  71% 597/837 [01:16<00:31,  7.68it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  71% 598/837 [01:16<00:31,  7.70it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  72% 599/837 [01:16<00:31,  7.66it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  72% 600/837 [01:17<00:30,  7.74it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  72% 601/837 [01:17<00:30,  7.76it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  72% 602/837 [01:17<00:30,  7.82it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  72% 603/837 [01:17<00:29,  7.87it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  72% 604/837 [01:17<00:29,  8.00it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  72% 605/837 [01:17<00:28,  8.24it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  72% 606/837 [01:17<00:28,  8.09it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  73% 607/837 [01:17<00:29,  7.86it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  73% 608/837 [01:18<00:29,  7.71it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  73% 609/837 [01:18<00:30,  7.58it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  73% 610/837 [01:18<00:30,  7.54it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  73% 611/837 [01:18<00:30,  7.49it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  73% 612/837 [01:18<00:30,  7.43it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  73% 613/837 [01:18<00:30,  7.44it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  73% 614/837 [01:18<00:30,  7.42it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  73% 615/837 [01:18<00:30,  7.38it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  74% 616/837 [01:19<00:29,  7.39it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  74% 617/837 [01:19<00:29,  7.40it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  74% 618/837 [01:19<00:29,  7.38it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  74% 619/837 [01:19<00:29,  7.37it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  74% 620/837 [01:19<00:29,  7.38it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  74% 621/837 [01:19<00:29,  7.38it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  74% 622/837 [01:19<00:29,  7.34it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  74% 623/837 [01:20<00:29,  7.38it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  75% 624/837 [01:20<00:28,  7.37it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  75% 625/837 [01:20<00:28,  7.35it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  75% 626/837 [01:20<00:28,  7.38it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  75% 627/837 [01:20<00:28,  7.39it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  75% 628/837 [01:20<00:28,  7.38it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  75% 629/837 [01:20<00:28,  7.43it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  75% 630/837 [01:20<00:27,  7.47it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  75% 631/837 [01:21<00:27,  7.54it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  76% 632/837 [01:21<00:27,  7.57it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  76% 633/837 [01:21<00:26,  7.62it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  76% 634/837 [01:21<00:26,  7.61it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  76% 635/837 [01:21<00:26,  7.67it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  76% 636/837 [01:21<00:26,  7.73it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  76% 637/837 [01:21<00:25,  7.74it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  76% 638/837 [01:22<00:25,  7.91it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  76% 639/837 [01:22<00:24,  8.23it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  76% 640/837 [01:22<00:24,  8.07it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  77% 641/837 [01:22<00:25,  7.81it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  77% 642/837 [01:22<00:25,  7.65it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  77% 643/837 [01:22<00:25,  7.60it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  77% 644/837 [01:22<00:25,  7.53it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  77% 645/837 [01:22<00:25,  7.46it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  77% 646/837 [01:23<00:25,  7.43it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  77% 647/837 [01:23<00:25,  7.41it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  77% 648/837 [01:23<00:25,  7.39it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  78% 649/837 [01:23<00:25,  7.38it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  78% 650/837 [01:23<00:25,  7.40it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  78% 651/837 [01:23<00:25,  7.37it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  78% 652/837 [01:23<00:25,  7.39it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  78% 653/837 [01:24<00:24,  7.38it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  78% 654/837 [01:24<00:24,  7.35it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  78% 655/837 [01:24<00:24,  7.34it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  78% 656/837 [01:24<00:24,  7.38it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  78% 657/837 [01:24<00:24,  7.37it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  79% 658/837 [01:24<00:24,  7.34it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  79% 659/837 [01:24<00:23,  7.48it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  79% 660/837 [01:24<00:23,  7.47it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  79% 661/837 [01:25<00:23,  7.55it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  79% 662/837 [01:25<00:23,  7.56it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  79% 663/837 [01:25<00:22,  7.59it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  79% 664/837 [01:25<00:22,  7.60it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  79% 665/837 [01:25<00:22,  7.64it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  80% 666/837 [01:25<00:21,  7.85it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  80% 667/837 [01:25<00:21,  8.08it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  80% 668/837 [01:25<00:20,  8.35it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  80% 669/837 [01:26<00:20,  8.05it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  80% 670/837 [01:26<00:21,  7.86it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  80% 671/837 [01:26<00:21,  7.71it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  80% 672/837 [01:26<00:21,  7.63it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  80% 673/837 [01:26<00:21,  7.55it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  81% 674/837 [01:26<00:21,  7.50it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  81% 675/837 [01:26<00:21,  7.52it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  81% 676/837 [01:27<00:21,  7.50it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  81% 677/837 [01:27<00:21,  7.46it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  81% 678/837 [01:27<00:21,  7.44it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  81% 679/837 [01:27<00:21,  7.43it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  81% 680/837 [01:27<00:21,  7.43it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  81% 681/837 [01:27<00:20,  7.44it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  81% 682/837 [01:27<00:20,  7.42it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  82% 683/837 [01:27<00:20,  7.45it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  82% 684/837 [01:28<00:20,  7.43it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  82% 685/837 [01:28<00:20,  7.49it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  82% 686/837 [01:28<00:20,  7.55it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  82% 687/837 [01:28<00:19,  7.55it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  82% 688/837 [01:28<00:19,  7.58it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  82% 689/837 [01:28<00:19,  7.64it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  82% 690/837 [01:28<00:19,  7.68it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  83% 691/837 [01:29<00:18,  7.80it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  83% 693/837 [01:29<00:16,  8.65it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  83% 694/837 [01:29<00:17,  8.32it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  83% 695/837 [01:29<00:17,  8.07it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  83% 696/837 [01:29<00:17,  7.89it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  83% 697/837 [01:29<00:18,  7.74it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  83% 698/837 [01:29<00:18,  7.62it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  84% 699/837 [01:30<00:18,  7.56it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  84% 700/837 [01:30<00:18,  7.52it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  84% 701/837 [01:30<00:18,  7.48it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  84% 702/837 [01:30<00:18,  7.48it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  84% 703/837 [01:30<00:17,  7.46it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  84% 704/837 [01:30<00:17,  7.41it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  84% 705/837 [01:30<00:17,  7.42it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  84% 706/837 [01:30<00:17,  7.41it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  84% 707/837 [01:31<00:17,  7.39it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  85% 708/837 [01:31<00:17,  7.48it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  85% 709/837 [01:31<00:16,  7.54it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  85% 710/837 [01:31<00:16,  7.61it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  85% 711/837 [01:31<00:16,  7.67it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  85% 712/837 [01:31<00:16,  7.71it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  85% 713/837 [01:31<00:15,  7.98it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  85% 714/837 [01:31<00:15,  8.17it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  85% 715/837 [01:32<00:15,  7.90it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  86% 716/837 [01:32<00:15,  7.78it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  86% 717/837 [01:32<00:15,  7.68it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  86% 718/837 [01:32<00:15,  7.62it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  86% 719/837 [01:32<00:15,  7.56it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  86% 720/837 [01:32<00:15,  7.48it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  86% 721/837 [01:32<00:15,  7.50it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  86% 722/837 [01:33<00:15,  7.48it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  86% 723/837 [01:33<00:15,  7.44it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  86% 724/837 [01:33<00:15,  7.45it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  87% 725/837 [01:33<00:15,  7.46it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  87% 726/837 [01:33<00:14,  7.46it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  87% 727/837 [01:33<00:14,  7.50it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  87% 728/837 [01:33<00:14,  7.53it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  87% 729/837 [01:33<00:14,  7.59it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  87% 730/837 [01:34<00:13,  7.68it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  87% 731/837 [01:34<00:13,  7.80it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  87% 732/837 [01:34<00:13,  8.00it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  88% 733/837 [01:34<00:13,  7.86it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  88% 734/837 [01:34<00:13,  7.71it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  88% 735/837 [01:34<00:13,  7.61it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  88% 736/837 [01:34<00:13,  7.57it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  88% 737/837 [01:35<00:13,  7.55it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  88% 738/837 [01:35<00:13,  7.53it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  88% 739/837 [01:35<00:13,  7.50it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  88% 740/837 [01:35<00:12,  7.48it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  89% 741/837 [01:35<00:12,  7.49it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  89% 742/837 [01:35<00:12,  7.43it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  89% 743/837 [01:35<00:12,  7.46it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  89% 744/837 [01:35<00:12,  7.55it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  89% 745/837 [01:36<00:11,  7.68it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  89% 746/837 [01:36<00:11,  7.81it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  89% 747/837 [01:36<00:11,  7.94it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  89% 748/837 [01:36<00:10,  8.17it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  89% 749/837 [01:36<00:11,  7.99it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  90% 750/837 [01:36<00:11,  7.82it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  90% 751/837 [01:36<00:11,  7.72it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  90% 752/837 [01:36<00:11,  7.67it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  90% 753/837 [01:37<00:11,  7.56it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  90% 754/837 [01:37<00:10,  7.57it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  90% 755/837 [01:37<00:10,  7.51it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  90% 756/837 [01:37<00:10,  7.48it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  90% 757/837 [01:37<00:10,  7.64it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  91% 758/837 [01:37<00:10,  7.75it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  91% 759/837 [01:37<00:09,  7.85it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  91% 760/837 [01:38<00:09,  7.94it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  91% 761/837 [01:38<00:09,  8.33it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  91% 762/837 [01:38<00:09,  8.22it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  91% 763/837 [01:38<00:09,  8.13it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  91% 764/837 [01:38<00:09,  8.10it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  91% 765/837 [01:38<00:08,  8.02it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  92% 766/837 [01:38<00:08,  7.99it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  92% 767/837 [01:38<00:08,  7.99it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  92% 768/837 [01:39<00:08,  7.90it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  92% 769/837 [01:39<00:08,  7.84it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  92% 770/837 [01:39<00:08,  7.88it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  92% 771/837 [01:39<00:08,  8.22it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  92% 772/837 [01:39<00:08,  7.92it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  92% 773/837 [01:39<00:08,  7.78it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  92% 774/837 [01:39<00:08,  7.69it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  93% 775/837 [01:39<00:08,  7.57it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  93% 776/837 [01:40<00:08,  7.57it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  93% 777/837 [01:40<00:07,  7.60it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  93% 778/837 [01:40<00:07,  7.66it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  93% 779/837 [01:40<00:07,  7.78it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  93% 780/837 [01:40<00:07,  8.10it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  93% 781/837 [01:40<00:07,  7.90it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  93% 782/837 [01:40<00:07,  7.77it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  94% 783/837 [01:40<00:07,  7.70it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  94% 784/837 [01:41<00:06,  7.64it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  94% 785/837 [01:41<00:06,  7.61it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  94% 786/837 [01:41<00:06,  7.63it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  94% 787/837 [01:41<00:06,  7.83it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  94% 788/837 [01:41<00:06,  8.07it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  94% 789/837 [01:41<00:06,  7.91it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  94% 790/837 [01:41<00:06,  7.75it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  95% 791/837 [01:41<00:05,  7.69it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  95% 792/837 [01:42<00:05,  7.76it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  95% 793/837 [01:42<00:05,  7.93it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  95% 794/837 [01:42<00:05,  8.35it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  95% 795/837 [01:42<00:05,  8.21it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  95% 796/837 [01:42<00:05,  8.15it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  95% 797/837 [01:42<00:04,  8.09it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  95% 798/837 [01:42<00:04,  8.04it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  95% 799/837 [01:42<00:04,  8.33it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  96% 800/837 [01:43<00:04,  8.08it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  96% 801/837 [01:43<00:04,  7.92it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  96% 802/837 [01:43<00:04,  7.96it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  96% 803/837 [01:43<00:04,  8.13it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  96% 804/837 [01:43<00:04,  8.10it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  96% 805/837 [01:43<00:03,  8.06it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  96% 806/837 [01:43<00:03,  8.11it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  96% 807/837 [01:43<00:03,  8.25it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  97% 808/837 [01:44<00:03,  8.04it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  97% 809/837 [01:44<00:03,  8.12it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  97% 810/837 [01:44<00:03,  8.48it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  97% 811/837 [01:44<00:03,  8.30it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  97% 812/837 [01:44<00:02,  8.37it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  97% 813/837 [01:44<00:02,  8.55it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  97% 814/837 [01:44<00:02,  8.49it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  97% 815/837 [01:44<00:02,  8.67it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  97% 816/837 [01:44<00:02,  8.77it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  98% 817/837 [01:45<00:02,  8.89it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  98% 818/837 [01:45<00:02,  8.75it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  98% 819/837 [01:45<00:02,  8.78it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  98% 820/837 [01:45<00:01,  8.67it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  98% 821/837 [01:45<00:01,  8.75it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  98% 822/837 [01:45<00:01,  9.03it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  98% 823/837 [01:45<00:01,  8.84it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  99% 825/837 [01:45<00:01,  9.43it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  99% 826/837 [01:46<00:01,  9.54it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  99% 827/837 [01:46<00:01,  9.41it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  99% 828/837 [01:46<00:00,  9.08it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  99% 829/837 [01:46<00:00,  9.07it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  99% 830/837 [01:46<00:00,  8.74it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  99% 831/837 [01:46<00:00,  8.54it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  99% 832/837 [01:46<00:00,  8.60it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset: 100% 833/837 [01:46<00:00,  8.78it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset: 100% 834/837 [01:47<00:00,  8.34it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset: 100% 836/837 [01:47<00:00, 10.50it/s]\u001b[A\n",
            "                                                                          \u001b[A2022-06-07 13:06:27 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 2.537 | nll_loss 0.788 | ppl 1.73 | wps 29882.2 | wpb 3824.5 | bsz 386.5 | num_updates 6979\n",
            "2022-06-07 13:06:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 6979 updates\n",
            "2022-06-07 13:06:27 | INFO | fairseq.trainer | Saving checkpoint to /content/gdrive/MyDrive/Tobigs/NLP_conference/jejueo/translation/train/4k/ko-je-bin/ckpt/checkpoint1.pt\n",
            "2022-06-07 13:06:29 | INFO | fairseq.trainer | Finished saving checkpoint to /content/gdrive/MyDrive/Tobigs/NLP_conference/jejueo/translation/train/4k/ko-je-bin/ckpt/checkpoint1.pt\n",
            "2022-06-07 13:06:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint train/4k/ko-je-bin/ckpt/checkpoint1.pt (epoch 1 @ 6979 updates, score 2.537) (writing took 5.701514942999893 seconds)\n",
            "2022-06-07 13:06:33 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)\n",
            "2022-06-07 13:06:33 | INFO | train | epoch 001 | loss 4.339 | nll_loss 3.093 | ppl 8.53 | wps 9781.8 | ups 2.51 | wpb 3893.6 | bsz 388.1 | num_updates 6979 | lr 0.000378533 | gnorm 2.179 | train_wall 2649 | gb_free 12.5 | wall 2780\n",
            "2022-06-07 13:06:33 | INFO | fairseq_cli.train | done training in 2778.9 seconds\n"
          ]
        }
      ],
      "source": [
        "!fairseq-train data/4k/ko-je-bin \\\n",
        "    --arch transformer       \\\n",
        "    --optimizer adam \\\n",
        "    --lr 0.0005 \\\n",
        "    --label-smoothing 0.1 \\\n",
        "    --dropout 0.3       \\\n",
        "    --max-tokens 4000 \\\n",
        "    --stop-min-lr '1e-09' \\\n",
        "    --lr-scheduler inverse_sqrt       \\\n",
        "    --weight-decay 0.0001 \\\n",
        "    --criterion label_smoothed_cross_entropy       \\\n",
        "    --max-epoch 1 \\\n",
        "    --warmup-updates 4000 \\\n",
        "    --warmup-init-lr '1e-07'    \\\n",
        "    --adam-betas '(0.9, 0.98)'       \\\n",
        "    --save-dir train/4k/ko-je-bin/ckpt  \\\n",
        "    --save-interval 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bXVUjuT0iuK0"
      },
      "source": [
        "# STEP 4. fairseq-generate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ztgUFN8bipvS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed978fe6-cb8c-48b2-8b03-0b353f3ad5fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-06-07 13:06:39 | INFO | fairseq_cli.generate | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': 'train/4k/ko-je-bin/ckpt/checkpoint_best.pt', 'post_process': 'sentencepiece', 'quiet': False, 'model_overrides': '{}', 'results_path': 'prediction'}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 12000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'wav2vec2', 'extractor_mode': 'default', 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': 'gelu', 'layer_type': 'transformer', 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.0, 'final_dim': 0, 'layer_norm_first': False, 'conv_feature_layers': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_bias': False, 'logit_temp': 0.1, 'quantize_targets': False, 'quantize_input': False, 'same_quantizer': False, 'target_glu': False, 'feature_grad_mult': 1.0, 'quantizer_depth': 1, 'quantizer_factor': 3, 'latent_vars': 320, 'latent_groups': 2, 'latent_dim': 0, 'mask_length': 10, 'mask_prob': 0.65, 'mask_selection': 'static', 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_before': False, 'mask_channel_selection': 'static', 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'num_negatives': 100, 'negatives_from_everywhere': False, 'cross_sample_negatives': 0, 'codebook_negatives': 0, 'conv_pos': 128, 'conv_pos_groups': 16, 'pos_conv_depth': 1, 'latent_temp': [2.0, 0.5, 0.999995], 'max_positions': 100000, 'checkpoint_activations': False, 'required_seq_len_multiple': 1, 'crop_seq_to_multiple': 1, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': False}, 'task': {'_name': 'translation', 'data': 'data/4k/ko-je-bin', 'source_lang': 'ko', 'target_lang': 'je', 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': False, 'eval_bleu_args': '{}', 'eval_bleu_detok': 'space', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': None, 'eval_bleu_print_samples': False}, 'criterion': {'_name': 'cross_entropy', 'sentence_avg': True}, 'optimizer': None, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'simul_type': None}\n",
            "2022-06-07 13:06:39 | INFO | fairseq.tasks.translation | [ko] dictionary: 4001 types\n",
            "2022-06-07 13:06:39 | INFO | fairseq.tasks.translation | [je] dictionary: 4001 types\n",
            "2022-06-07 13:06:39 | INFO | fairseq_cli.generate | loading model(s) from train/4k/ko-je-bin/ckpt/checkpoint_best.pt\n",
            "2022-06-07 13:06:41 | INFO | fairseq.data.data_utils | loaded 323,487 examples from: data/4k/ko-je-bin/test.ko-je.ko\n",
            "2022-06-07 13:06:41 | INFO | fairseq.data.data_utils | loaded 323,487 examples from: data/4k/ko-je-bin/test.ko-je.je\n",
            "2022-06-07 13:06:41 | INFO | fairseq.tasks.translation | data/4k/ko-je-bin test ko-je 323487 examples\n",
            "2022-06-07 13:36:27 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
            "2022-06-07 13:36:27 | INFO | fairseq_cli.generate | Translated 323,487 sentences (3,116,914 tokens) in 600.3s (538.91 sentences/s, 5192.61 tokens/s)\n"
          ]
        }
      ],
      "source": [
        "!fairseq-generate data/4k/ko-je-bin \\\n",
        "  --path train/4k/ko-je-bin/ckpt/checkpoint_best.pt \\\n",
        "  --source-lang ko --target-lang je \\\n",
        "  --valid-subset 'valid' \\\n",
        "  --gen-subset 'test' \\\n",
        "  --beam 5 \\\n",
        "  --remove-bpe 'sentencepiece'\\\n",
        "  --results-path prediction"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!grep '^H' prediction/generate-test.txt | cut -f3- > prediction/gen.out.sys # 예측된 문장 (H)\n",
        "!grep '^T' prediction/generate-test.txt | cut -f2- > prediction/gen.out.ref # 타겟(정답) 문장 (T)"
      ],
      "metadata": {
        "id": "3Rz_B7Nz5OuE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# STEP6. Evaluation"
      ],
      "metadata": {
        "id": "dVPf8AD1BPDQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## 최종 BLEU score 확인\n",
        "!fairseq-score \\\n",
        "--sys prediction/gen.out.sys \\\n",
        "--ref prediction/gen.out.ref"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "emzVRwsT8jFc",
        "outputId": "d3f59f65-223e-41a4-d255-657722f4a9a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(ignore_case=False, order=4, ref='prediction/gen.out.ref', sacrebleu=False, sentence_bleu=False, sys='prediction/gen.out.sys')\n",
            "BLEU4 = 73.24, 85.9/76.0/69.2/63.7 (BP=1.000, ratio=1.000, syslen=1834892, reflen=1835050)\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "transformer_translation.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}